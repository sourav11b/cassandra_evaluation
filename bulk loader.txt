package org.personal.cassandra.evaluation;

import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.InputStreamReader;
import java.math.BigDecimal;
import java.net.HttpURLConnection;
import java.net.URL;
import java.text.DateFormat;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Date;
import java.util.List;

import org.supercsv.io.CsvListReader;
import org.supercsv.prefs.CsvPreference;

import org.apache.cassandra.config.Config;
import org.apache.cassandra.dht.Murmur3Partitioner;
import org.apache.cassandra.exceptions.InvalidRequestException;
import org.apache.cassandra.io.sstable.CQLSSTableWriter;

public class BulkUploadUsingSSTables {

	/** Keyspace name */
	public static final String KEYSPACE = "evaluation";
	/** Table name */
	//public static final String TABLE = "flights";
	//public static final String TABLE = "flights_by_airport_time_ordered";
	public static final String TABLE = "flights_by_air_time_buckets";

	public static final String DEFAULT_OUTPUT_DIR = "./data";
/*	public static final String SCHEMA = 
			"CREATE TABLE evaluation.flights ("
			+ "           	  	ID int PRIMARY KEY,"
			+ "             	  	YEAR int,  "
			+ "    	  	             	  	DAY_OF_MONTH int, "
			+ "            	  	FL_DATE timestamp, "
			+ "            	  	AIRLINE_ID int,      "
			+ "       	  	CARRIER varchar,     "
			+ "        	  	FL_NUM int,         "
			+ "    	  	ORIGIN_AIRPORT_ID int,   "
			+ "          	  	ORIGIN varchar,   "
			+ "          	  	ORIGIN_CITY_NAME varchar,  "
			+ "           	  	ORIGIN_STATE_ABR varchar,  "
			+ "           	  	DEST varchar,     "
			+ "        	  	DEST_CITY_NAME varchar,  "
			+ "           	  	DEST_STATE_ABR varchar,"
			+ "            	  	DEP_TIME timestamp,   "
			+ "          	  	ARR_TIME timestamp,    "
			+ "         	  	ACTUAL_ELAPSED_TIME timestamp, "
			+ "            	  	AIR_TIME timestamp,   "
			+ "          	  	DISTANCE int)";
			
			*/
	
/*	public static final String SCHEMA = "CREATE TABLE evaluation.flights_by_airport_time_ordered  	  (  	     id                  INT , "
			+ " 	     year                INT,  	     day_of_month        INT,  	     fl_date             TIMESTAMP,  	     airline_id          INT,  	     carrier             VARCHAR,  	     fl_num              INT,  	     origin_airport_id   INT,  	"
			+ "     origin              VARCHAR, "
			+ " 	     origin_city_name    VARCHAR, "
			+ " 	     origin_state_abr    VARCHAR,  	"
			+ "     dest                VARCHAR,  	"
			+ "     dest_city_name      VARCHAR,  "
			+ "	     dest_state_abr      VARCHAR,  	 "
			+ "    dep_time            TIMESTAMP,  "
			+ "	     arr_time            TIMESTAMP,  "
			+ "	     actual_elapsed_time TIMESTAMP,  "
			+ "	     air_time            TIMESTAMP,  	 "
			+ "    distance            INT, "
			+ " 	    PRIMARY KEY (origin,fl_date,dep_time,fl_num)" + 
			") WITH CLUSTERING ORDER BY (fl_date ASC,dep_time ASC)";
			*/
	
	/*public static final String SCHEMA = "CREATE TABLE evaluation.flights_by_airport_time_ordered  	  (  	     id                  INT , "
			+ " 	     year                INT,  	     day_of_month        INT,  	     fl_date             TIMESTAMP,  	     airline_id          INT,  	     carrier             VARCHAR,  	     fl_num              INT,  	     origin_airport_id   INT,  	"
			+ "     origin              VARCHAR, "
			+ " 	     origin_city_name    VARCHAR, "
			+ " 	     origin_state_abr    VARCHAR,  	"
			+ "     dest                VARCHAR,  	"
			+ "     dest_city_name      VARCHAR,  "
			+ "	     dest_state_abr      VARCHAR,  	 "
			+ "    dep_time            TIMESTAMP,  "
			+ "	     arr_time            TIMESTAMP,  "
			+ "	     actual_elapsed_time TIMESTAMP,  "
			+ "	     air_time            TIMESTAMP,  	 "
			+ "    distance            INT, "
			+ " 	    PRIMARY KEY (origin,fl_date,dep_time,fl_num,id)" + 
			") WITH CLUSTERING ORDER BY (fl_date ASC,dep_time ASC)";
	*/
	public static final String SCHEMA = "CREATE TABLE evaluation.flights_by_air_time_buckets(" + 
			"     id                  INT ," + 
			"" + 
			"     carrier             VARCHAR," + 
			"" + 
			"     origin              VARCHAR," + 
			"" + 
			"     dest                VARCHAR," + 
			"" + 
			"     air_time            timestamp," + 
			"     air_time_bucket int," + 
			" " + 
			"  PRIMARY KEY (air_time_bucket,id)" + 
			") ";
		

	/**
	 * INSERT statement to bulk load. It is like prepared statement. You fill in
	 * place holder for each data.
	 */
	   
	   // public static final String INSERT_STMT =  "INSERT INTO evaluation.flights  "+"(ID,YEAR,DAY_OF_MONTH,FL_DATE,AIRLINE_ID,CARRIER,FL_NUM,"+"ORIGIN_AIRPORT_ID,ORIGIN,ORIGIN_CITY_NAME,ORIGIN_STATE_ABR,"+"DEST,DEST_CITY_NAME,DEST_STATE_ABR,DEP_TIME,ARR_TIME,ACTUAL_ELAPSED_TIME,"+"AIR_TIME,DISTANCE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)";
	    public static final String INSERT_STMT =  "INSERT INTO evaluation.flights_by_air_time_buckets  "+"(ID,CARRIER,ORIGIN,DEST,air_time,air_time_BUCKET) VALUES (?, ?, ?, ?, ?, ?)";

	public static void main(String[] args) {
		
		int count = 0;
		try {
			File outputDir = new File(DEFAULT_OUTPUT_DIR + File.separator + KEYSPACE + File.separator + TABLE);
			if (!outputDir.exists() && !outputDir.mkdirs()) {
				throw new RuntimeException("Cannot create output directory: " + outputDir);
			}

			CQLSSTableWriter writer = CQLSSTableWriter.builder()
					// set target schema
					
					.forTable(SCHEMA)
					// set CQL statement to put data
					.using(INSERT_STMT)
					.inDirectory(outputDir)
					// set partitioner if needed
					// default is Murmur3Partitioner so set if you use different one.
					.withPartitioner(new Murmur3Partitioner()).build();
			CsvListReader csvReader = null;

			BufferedReader reader = new BufferedReader(new InputStreamReader(new FileInputStream(
					new File("/home/datastax/multi-node/sample data/flights/flights_from_pg.csv"))));
			csvReader = new CsvListReader(reader, CsvPreference.STANDARD_PREFERENCE);
		

			List<String> data;
			while ((data = csvReader.read()) != null) {
				
				count ++;
				
				//System.out.println("line number : "+count);

				DateFormat dtFormat = new SimpleDateFormat("yyyy/MM/dd");
				Date flDate = dtFormat.parse(data.get(3));
				//System.out.println("Index: " + data.get(0));

				SimpleDateFormat timeformat = new SimpleDateFormat("HH:mm"); // 12
																				// hour
																				// format
		
				
				Date depTime = timeformat.parse(fixTimeformat(data.get(14)));
				Date arrTime = timeformat.parse(fixTimeformat(data.get(15)));
				Date elapsedTime = timeformat.parse(fixTimeformat(data.get(16)));
				Date airTime=timeformat.parse(fixTimeformat(data.get(17)));
				
				Calendar cal=Calendar.getInstance();
				cal.setTime(airTime);
				int unroundedMinutes = cal.get(Calendar.MINUTE);
				int mod = unroundedMinutes % 10;
				cal.add(Calendar.MINUTE, mod ==0 ? mod :(10-mod));
				
			System.out.println(
				Integer.parseInt(data.get(0))+" || "+			
				data.get(5)+" || "+	
				data.get(8)+" || "+	
				data.get(11)+" || "+	
				airTime+" || "+	
				cal.getTime()
								
				
				);
			if(count > 10) {
			break;
			}
				/*writer.addRow(
						Integer.parseInt(data.get(0)),
						Integer.parseInt(data.get(1)),
						Integer.parseInt(data.get(2)),
						flDate,
						Integer.parseInt(data.get(4)),
						data.get(5),
						Integer.parseInt(data.get(6)),
						Integer.parseInt(data.get(7)),
						data.get(8),
						data.get(9),
						data.get(10),
						data.get(11),
						data.get(12),
						data.get(13),
						depTime, 
						arrTime,
						elapsedTime,						
						timeformat.parse(fixTimeformat(data.get(17))),
						Integer.parseInt(data.get(18)));*/
				
//				writer.addRow(
//						Integer.parseInt(data.get(0)),
//					
//						data.get(5),
//						data.get(8),
//						data.get(11),
//						airTime,
//						cal.getTime()
//										
//						
//						);
				
//				if(count%10000==0) {
//					writer.close();
//					System.out.println("Processed 10000");
//					writer = CQLSSTableWriter.builder()
//							// set target schema
//							
//							.forTable(SCHEMA)
//							// set CQL statement to put data
//							.using(INSERT_STMT)
//							.inDirectory(outputDir)
//							// set partitioner if needed
//							// default is Murmur3Partitioner so set if you use different one.
//							.withPartitioner(new Murmur3Partitioner()).build();
//				}

			}

			writer.close();
		} catch (InvalidRequestException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (NumberFormatException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (FileNotFoundException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (ParseException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}

		System.out.println("Done creating sstables with count :"+count);

	}

	private static String fixTimeformat(String data) {
		// System.out.println(data);
		if (data.length() == 2) {
			data = "00" + data;
		}
		if (data.length() == 1) {
			data = data + "000";
		}

		data = new StringBuilder(data).insert(data.length() - 2, ":").toString();
		return data;
	}

}
